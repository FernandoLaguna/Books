{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62cddb16",
   "metadata": {},
   "source": [
    " # Predicting Book Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c45e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "from path import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40bea4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Rating Count</th>\n",
       "      <th>Language_Dummy</th>\n",
       "      <th>Size_Dummy</th>\n",
       "      <th>Famous_Dummy</th>\n",
       "      <th>Categories_Dummy</th>\n",
       "      <th>Serie_Dummy</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Rating_Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>4.49</td>\n",
       "      <td>7.38</td>\n",
       "      <td>870</td>\n",
       "      <td>1996446</td>\n",
       "      <td>English</td>\n",
       "      <td>Big</td>\n",
       "      <td>Famous</td>\n",
       "      <td>Top_Category</td>\n",
       "      <td>Serie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High_Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.780320e+12</td>\n",
       "      <td>3.59</td>\n",
       "      <td>2.10</td>\n",
       "      <td>498</td>\n",
       "      <td>4367341</td>\n",
       "      <td>English</td>\n",
       "      <td>Big</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Serie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low_Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.780350e+12</td>\n",
       "      <td>4.59</td>\n",
       "      <td>21.15</td>\n",
       "      <td>1728</td>\n",
       "      <td>97731</td>\n",
       "      <td>English</td>\n",
       "      <td>Big</td>\n",
       "      <td>Famous</td>\n",
       "      <td>Top_Category</td>\n",
       "      <td>Serie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High_Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.780390e+12</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.73</td>\n",
       "      <td>464</td>\n",
       "      <td>1041597</td>\n",
       "      <td>English</td>\n",
       "      <td>Big</td>\n",
       "      <td>Other</td>\n",
       "      <td>Top_Category</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low_Rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.780140e+12</td>\n",
       "      <td>4.11</td>\n",
       "      <td>5.46</td>\n",
       "      <td>532</td>\n",
       "      <td>1328143</td>\n",
       "      <td>English</td>\n",
       "      <td>Big</td>\n",
       "      <td>Other</td>\n",
       "      <td>Top_Category</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High_Rating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ISBN  Rating  Price  Pages  Rating Count Language_Dummy Size_Dummy  \\\n",
       "0  9.780440e+12    4.49   7.38    870       1996446        English        Big   \n",
       "1  9.780320e+12    3.59   2.10    498       4367341        English        Big   \n",
       "2  9.780350e+12    4.59  21.15   1728         97731        English        Big   \n",
       "3  9.780390e+12    3.84   2.73    464       1041597        English        Big   \n",
       "4  9.780140e+12    4.11   5.46    532       1328143        English        Big   \n",
       "\n",
       "  Famous_Dummy Categories_Dummy Serie_Dummy  Unnamed: 10 Rating_Classification  \n",
       "0       Famous     Top_Category       Serie          NaN           High_Rating  \n",
       "1        Other            Other       Serie          NaN            Low_Rating  \n",
       "2       Famous     Top_Category       Serie          NaN           High_Rating  \n",
       "3        Other     Top_Category       Other          NaN            Low_Rating  \n",
       "4        Other     Top_Category       Other          NaN           High_Rating  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the dataset\n",
    "data = Path('books_clean.csv')\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "# We can see from the preview of the DataFrame that multiple variables (also called features), such as the isbn13,\n",
    "#published_year, average_rating, num_pages, ratings_count, can be used to predict the outcome: whether a book will have a good \n",
    "#rating (1) or will not (0) based on the fact that an average rating below of 4.5 will not likely be successful\n",
    "\n",
    "df.loc[df['Rating'] <= 4.0, 'Rating_Classification'] = 'Low_Rating' \n",
    "df.loc[df['Rating'] > 4.0, 'Rating_Classification'] = 'High_Rating'\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b40a038d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISBN                     float64\n",
       "Rating                   float64\n",
       "Price                    float64\n",
       "Pages                      int64\n",
       "Rating Count               int64\n",
       "Language_Dummy            object\n",
       "Size_Dummy                object\n",
       "Famous_Dummy              object\n",
       "Categories_Dummy          object\n",
       "Serie_Dummy               object\n",
       "Unnamed: 10              float64\n",
       "Rating_Classification     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will check for the variables from all columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05e1be63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1931"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the current NaN values from the dataframe\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07b16ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all the NaN values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33abbfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recount all the NaN values to make sure they are dropped\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cb8b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use method to convert String to int\n",
    "def rating(x):\n",
    "    if x == 'Low_Rating':\n",
    "        return 0\n",
    "    if x == 'High_Rating':\n",
    "        return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d58b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the method to the rating_classification column\n",
    "df['Rating_Classification'] = df['Rating_Classification'].apply(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9bbf802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use method to convert String to int\n",
    "def binary(x):\n",
    "    if x == 'Other':\n",
    "        return 0\n",
    "    if x == 'English'or 'Big' or 'Famous' or 'Serie' or 'Top_Category':\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "741e2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the method to the rating_classification column\n",
    "df['Size_Dummy'] = df['Size_Dummy'].apply(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ea99c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Serie_Dummy'] = df['Serie_Dummy'].apply(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e85b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Famous_Dummy'] = df['Famous_Dummy'].apply(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07897423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Language_Dummy'] = df['Language_Dummy'].apply(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1932671",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Categories_Dummy'] = df['Categories_Dummy'].apply(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d950b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Rating Count</th>\n",
       "      <th>Language_Dummy</th>\n",
       "      <th>Size_Dummy</th>\n",
       "      <th>Famous_Dummy</th>\n",
       "      <th>Categories_Dummy</th>\n",
       "      <th>Serie_Dummy</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Rating_Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ISBN, Rating, Price, Pages, Rating Count, Language_Dummy, Size_Dummy, Famous_Dummy, Categories_Dummy, Serie_Dummy, Unnamed: 10, Rating_Classification]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new dataframe with the target variables\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b5d523",
   "metadata": {},
   "source": [
    "##  Separate the Features (X) from the Target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c4fd6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Outcome column is defined as y, or the target.\n",
    "#X, or features, is created by dropping the Outcome column from the DataFrame.\n",
    "\n",
    "y = df[\"Rating_Classification\"]\n",
    "X = df.drop(columns=[\"Rating_Classification\",\"ISBN\",\"Rating\",\"Rating Count\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a345b",
   "metadata": {},
   "source": [
    " ## Split our data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d92082b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1448, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We first split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "743bb8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examining the shape of the training set with X_train.shape returned (1636,5), meaning that there are 1636 samples (rows) and \n",
    "#five features (columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3ae9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next step was to create a logistic regression model with the specified arguments for solver, max_iter, and random_state\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1580c600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200, random_state=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we trained the model with the training data\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3a4e996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction  Actual\n",
       "463           0       0\n",
       "464           0       0\n",
       "465           0       0\n",
       "466           0       0\n",
       "467           0       0\n",
       "468           0       0\n",
       "469           0       0\n",
       "470           0       0\n",
       "471           0       0\n",
       "472           0       0\n",
       "473           0       0\n",
       "474           0       0\n",
       "475           0       0\n",
       "476           0       0\n",
       "477           0       0\n",
       "478           0       0\n",
       "479           0       0\n",
       "480           0       0\n",
       "481           0       0\n",
       "482           0       0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To create predictions for y-values, we used the X_test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.tail(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab3587f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9855072463768116\n"
     ]
    }
   ],
   "source": [
    "#The final step is to measure the accuracy of the logistic regression model created\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "283d57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking into account that the accuracy score is simply the percentage of predictions that are correct. In this case, \n",
    "#the model's accuracy score was 0.9834, meaning that the model was correct 98.34% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04bc3140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          474            1\n",
       "Actual 1            6            2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  import the relevant modules for validation and print the confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "matrix_df = pd.DataFrame(\n",
    "    matrix, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a9be58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       475\n",
      "           1       0.67      0.25      0.36         8\n",
      "\n",
      "    accuracy                           0.99       483\n",
      "   macro avg       0.83      0.62      0.68       483\n",
      "weighted avg       0.98      0.99      0.98       483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report of sensitivity, precission and F1. La línea 0 se aplica al predictor de diabetes como hipótesis alternativa\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868862f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
